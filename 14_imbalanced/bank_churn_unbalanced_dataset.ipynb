{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bank_churn.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col = ['Surname', 'RowNumber', 'CustomerId']\n",
    "df.drop(columns=drop_col, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  int64  \n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_col_values(df):\n",
    "    for col in df:\n",
    "        print(f'{col} : {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography : ['France' 'Spain' 'Germany']\n",
      "Gender : ['Female' 'Male']\n",
      "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited : [1 0]\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037 7963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14574b0d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYOUlEQVR4nO3dfZBU9b3n8fdHQB4Ur4ijxWXcDHsLWQFxlAmSdYMaH0BiBFPrOkYjlm7wgZSYmES4qQ1YcRISvTFrJZjygRU3EUQThRjNxbC5Ye+WNzjoGBkJBbmwMsIKYiC4qxbgd//oH6QdB+aBnp6W3+dV1dWnv33O6W+38pkzv/PrM4oIzMwsD0f1dANmZlY+Dn0zs4w49M3MMuLQNzPLiEPfzCwjvXu6gfaceOKJUVNT09NtmJl9rKxevfqtiKhqXa/40K+pqaGxsbGn2zAz+1iR9L/bqnt4x8wsIw59M7OMOPTNzDJS8WP6ZnZk2LNnDy0tLbz33ns93coRpV+/flRXV9OnT58Ore/QN7OyaGlpYeDAgdTU1CCpp9s5IkQEO3bsoKWlhWHDhnVoGw/vmFlZvPfeewwePNiBX0KSGDx4cKd+e3Lom1nZOPBLr7OfqUPfzCwjDn0z6xlSaW8d0KtXL2praw/c5s2bd8j1J0+ezM6dO9m5cyfz58/v9FucO3cu99xzz4dqzc3NnHrqqbz77rsHap/97GdZvHhxp/ffFT6Ra+jOzv/KHXP8x3fs46d///40NTV1eP1nn30WgE2bNjF//nxuueWWw+5h1KhRfP7zn6ehoYG77rqLp59+mj179lBfX3/Y++4IH+mbWdZ27drFiBEjWLduHQBXXXUVDz74IFC4DMxbb73FrFmz+NOf/kRtbS1f//rXAbj77rv55Cc/yZgxY5gzZ86B/TU0NDBixAguvPDCA/ts7Vvf+hZPPPEETU1NzJo1ix//+MesXr2ac889l7FjxzJx4kS2bt0KwH333cfIkSMZM2ZMSX4w+EjfzLLx7rvvUltbe+Dx7NmzufLKK/nRj37Eddddx8yZM/nzn//Ml770pQ9tN2/ePNasWXPgt4Tly5ezfv16Vq1aRURw2WWXsXLlSo455hgWL17Myy+/zN69eznrrLMYO3YsAD/5yU8AuOmmmxgwYAD33HMPEyZM4Ktf/So1NTWce+65LF26lKqqKh5//HG++c1vsmDBAubNm8fGjRvp27cvO3fuPOzPwKFvZtk42PDORRddxBNPPMGMGTN45ZVX2t3P8uXLWb58OWeeeSYA77zzDuvXr2f37t1cfvnlDBgwAIDLLrvswDY33XTTh/bxuc99juOPP55bbrmFdevWsWbNGi666CIA9u3bx5AhQwAYM2YMV199NVOnTmXq1Kldedsf4tA3s+x98MEHrF27lv79+/P2229TXV19yPUjgtmzZ3PjjTd+qP7DH/6wU1MojzrqKI466igiglGjRvHCCy98ZJ1f/epXrFy5kmXLlvHtb3+b5uZmevfuenR7TN/Msnfvvfdy2mmnsWjRIq6//nr27NnzoecHDhzI7t27DzyeOHEiCxYs4J133gHgjTfeYNu2bUyYMIGnnnqKd999l927d/PLX/6yQ68/YsQItm/ffiD09+zZQ3NzMx988AGbN2/m/PPP5/vf/z47d+488Jpd5SN9M+sZUf4ZYK3H9CdNmsT111/PQw89xKpVqxg4cCATJkzgrrvu4s477zyw3uDBgznnnHMYPXo0l1xyCXfffTdr167lU5/6FADHHnssP/3pTznrrLO48sorqa2t5ROf+ASf/vSnD+yjeEy/taOPPponn3ySW2+9lV27drF3715uu+02Tj31VK655hp27dpFRPCVr3yF448//rA+A0U7H7ykfsBKoC+FHxJPRsQcSScAjwM1wCbgP0XEn9M2s4EbgH3ArRHxj6k+FngE6A88C8yMdhqoq6sL/xGV7uUpm1YOa9eu5bTTTuvpNo5IbX22klZHRF3rdTsyvPM+8JmIOAOoBSZJGg/MAlZExHBgRXqMpJFAPTAKmATMl9Qr7et+YDowPN0mdfrdmZlZl7Ub+lGwfxCpT7oFMAVYmOoLgalpeQqwOCLej4iNwAZgnKQhwHER8UI6un+0aBszMyuDDp3IldRLUhOwDXg+In4PnBwRWwHS/Ulp9aHA5qLNW1JtaFpuXW/r9aZLapTUuH379k68HTMzO5QOhX5E7IuIWqCawlH76EOs3tYAcRyi3tbrPRARdRFRV1X1kT/mbmZmXdSpKZsRsRP4Jwpj8W+mIRvS/ba0WgtwStFm1cCWVK9uo25mZmXSbuhLqpJ0fFruD1wI/BFYBkxLq00DlqblZUC9pL6ShlE4YbsqDQHtljRehW8vXFu0jZmZlUFH5ukPARamGThHAUsi4hlJLwBLJN0AvA5cARARzZKWAK8Be4EZEbEv7etm/jpl87l0M7MMdWWq8KF0ZBpxr169OP300w88rq+vZ9asWQddf/LkyTz22GMAPPbYY52+yubcuXM59thj+drXvvah+iOPPML1119PU1MTY8aMAWD06NE888wz1NTUdOo1Oqvd0I+IPwBntlHfAVxwkG0agIY26o3Aoc4HmJl1m0q4tPJ+1dXVNDQ08Pjjj5dsnx3hyzCYWdZ64tLKAJdeeinNzc1trrNo0SJOP/10Ro8ezR133FHKt+vLMJhZPirl0spQuNjaN77xDb7zne+wcOHCA6+1ZcsW7rjjDlavXs2gQYO4+OKLefrpp0tyhU1w6JtZRirp0soAX/jCF2hoaGDjxo0Hai+++CLnnXce+6erX3311axcubJkoe/hHTPLXutLK7dn/6WVm5qaaGpqYsOGDdxwww0Anbq0cu/evbn99tv53ve+96F9dyeHvpllrycvrXzdddfxm9/8hv1XHzj77LP53e9+x1tvvcW+fftYtGgR5557bsneq4d3zKxH9MSVWivx0spHH300t956KzNnzgRgyJAhfPe73+X8888nIpg8eTJTpkwp2WfQ7qWVe5ovrdz9fGllKwdfWrn7lPrSymZmdoRw6JuZZcShb2ZlU+nDyR9Hnf1MHfpmVhb9+vVjx44dDv4Sigh27NhBv379OryNZ++YWVlUV1fT0tKC/zBSafXr14/q6ur2V0wc+mZWFn369GHYsGE93Ub2PLxjZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGWk39CWdIum3ktZKapY0M9XnSnpDUlO6TS7aZrakDZLWSZpYVB8r6dX03H3qzF8QNjOzw9aRC67tBW6PiJckDQRWS3o+PXdvRNxTvLKkkUA9MAr4W+A3kk6NiH3A/cB04F+AZ4FJwHOleStmZtaedo/0I2JrRLyUlncDa4Ghh9hkCrA4It6PiI3ABmCcpCHAcRHxQhQuqP0oMPVw34CZmXVcp8b0JdUAZwK/T6UvS/qDpAWSBqXaUGBz0WYtqTY0Lbeut/U60yU1Smr0tbfNzEqnw6Ev6Vjg58BtEfEXCkM1fwfUAluBf9i/ahubxyHqHy1GPBARdRFRV1VV1dEWzcysHR0KfUl9KAT+zyLiFwAR8WZE7IuID4AHgXFp9RbglKLNq4EtqV7dRt3MzMqkI7N3BDwMrI2IHxTVhxStdjmwJi0vA+ol9ZU0DBgOrIqIrcBuSePTPq8FlpbofZiZWQd0ZPbOOcAXgVclNaXa3wNXSaqlMESzCbgRICKaJS0BXqMw82dGmrkDcDPwCNCfwqwdz9wxMyujdkM/Iv6Ztsfjnz3ENg1AQxv1RmB0Zxo0M7PS8Tdyzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCPthr6kUyT9VtJaSc2SZqb6CZKel7Q+3Q8q2ma2pA2S1kmaWFQfK+nV9Nx9ktQ9b8vMzNrSkSP9vcDtEXEaMB6YIWkkMAtYERHDgRXpMem5emAUMAmYL6lX2tf9wHRgeLpNKuF7MTOzdrQb+hGxNSJeSsu7gbXAUGAKsDCtthCYmpanAIsj4v2I2AhsAMZJGgIcFxEvREQAjxZtY2ZmZdC7MytLqgHOBH4PnBwRW6Hwg0HSSWm1ocC/FG3Wkmp70nLrugG6s/MjXTEnuqETMzuSdfhErqRjgZ8Dt0XEXw61ahu1OES9rdeaLqlRUuP27ds72qKZmbWjQ6EvqQ+FwP9ZRPwild9MQzak+22p3gKcUrR5NbAl1avbqH9ERDwQEXURUVdVVdXR92JmZu3oyOwdAQ8DayPiB0VPLQOmpeVpwNKier2kvpKGUThhuyoNBe2WND7t89qibczMrAw6MqZ/DvBF4FVJTan298A8YImkG4DXgSsAIqJZ0hLgNQozf2ZExL603c3AI0B/4Ll0MzOzMmk39CPin2l7PB7ggoNs0wA0tFFvBEZ3pkEzMysdfyPXzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLSLuhL2mBpG2S1hTV5kp6Q1JTuk0uem62pA2S1kmaWFQfK+nV9Nx9klT6t2NmZofSkSP9R4BJbdTvjYjadHsWQNJIoB4YlbaZL6lXWv9+YDowPN3a2qeZmXWjdkM/IlYCb3dwf1OAxRHxfkRsBDYA4yQNAY6LiBciIoBHgald7NnMzLrocMb0vyzpD2n4Z1CqDQU2F63TkmpD03LrepskTZfUKKlx+/bth9GimZkV62ro3w/8HVALbAX+IdXbGqePQ9TbFBEPRERdRNRVVVV1sUUzM2utS6EfEW9GxL6I+AB4EBiXnmoBTilatRrYkurVbdTNzKyMuhT6aYx+v8uB/TN7lgH1kvpKGkbhhO2qiNgK7JY0Ps3auRZYehh9m5lZF/RubwVJi4DzgBMltQBzgPMk1VIYotkE3AgQEc2SlgCvAXuBGRGxL+3qZgozgfoDz6WbmZmVUbuhHxFXtVF++BDrNwANbdQbgdGd6s7MzErK38g1M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjLQ7T9+su+nOzv1phZhz0Ms2mVk7fKRvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llpN3Ql7RA0jZJa4pqJ0h6XtL6dD+o6LnZkjZIWidpYlF9rKRX03P3SercX84wM7PD1pEj/UeASa1qs4AVETEcWJEeI2kkUA+MStvMl9QrbXM/MB0Ynm6t92lmZt2s3dCPiJXA263KU4CFaXkhMLWovjgi3o+IjcAGYJykIcBxEfFCRATwaNE2ZmZWJl0d0z85IrYCpPuTUn0osLlovZZUG5qWW9fbJGm6pEZJjdu3b+9ii2Zm1lqpT+S2NU4fh6i3KSIeiIi6iKirqqoqWXNmZrnraui/mYZsSPfbUr0FOKVovWpgS6pXt1E3M7My6mroLwOmpeVpwNKier2kvpKGUThhuyoNAe2WND7N2rm2aBszMyuT3u2tIGkRcB5woqQWYA4wD1gi6QbgdeAKgIholrQEeA3YC8yIiH1pVzdTmAnUH3gu3czMrIzaDf2IuOogT11wkPUbgIY26o3A6E51Z2ZmJeVv5JqZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGevd0A5VEd6rT28Sc6IZOPsbU+c+QuSXvwswO4rCO9CVtkvSqpCZJjal2gqTnJa1P94OK1p8taYOkdZImHm7zZmbWOaUY3jk/Imojoi49ngWsiIjhwIr0GEkjgXpgFDAJmC+pVwle38zMOqg7xvSnAAvT8kJgalF9cUS8HxEbgQ3AuG54fTMzO4jDDf0AlktaLWl6qp0cEVsB0v1JqT4U2Fy0bUuqfYSk6ZIaJTVu3779MFs0M7P9DvdE7jkRsUXSScDzkv54iHXbOsPX5lnQiHgAeACgrq7OZ0rNzErksI70I2JLut8GPEVhuOZNSUMA0v22tHoLcErR5tXAlsN5fTsIqXM3M8tGl0Nf0jGSBu5fBi4G1gDLgGlptWnA0rS8DKiX1FfSMGA4sKqrr2/2EZ39YecfeJahwxneORl4SoV/OL2BxyLi15JeBJZIugF4HbgCICKaJS0BXgP2AjMiYt9hdW9mZp3S5dCPiH8FzmijvgO44CDbNAANXX1NMzM7PL4Mg5lZRhz6ZmYZ8bV3LGudvd6Sr7VkH3c+0jczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsI56yaVYKXbmOT3j6p5WfQ9+sh/g7AtYTPLxjZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh3538Z/tM7MK5CmbZhnydNF8+UjfzCwjPtI3s7Lybxk9y0f6ZmYZceibmWXEoW9mlhGHvtnHXWenB3uKcNbKHvqSJklaJ2mDpFnd/GL+h2BmVqSsoS+pF/Bj4BJgJHCVpJHl7MHMLGflnrI5DtgQEf8KIGkxMAV4rcx9mFkpdOU35Lkl76LDPF0UFGX86z2S/iMwKSL+c3r8ReDsiPhyq/WmA9PTwxHAuhK2cSLwVgn3113cZ2m5z9Jyn6XVHX1+IiKqWhfLfaTf1o/Zj/zUiYgHgAe6pQGpMSLqumPfpeQ+S8t9lpb7LK1y9lnuE7ktwClFj6uBLWXuwcwsW+UO/ReB4ZKGSToaqAeWlbkHM7NslXV4JyL2Svoy8I9AL2BBRDSXswe6adioG7jP0nKfpeU+S6tsfZb1RK6ZmfUsfyPXzCwjDn0zs4wc0aEv6RRJv5W0VlKzpJmpfoKk5yWtT/eDerjPfpJWSXol9XlnJfaZeuol6WVJz1RqjwCSNkl6VVKTpMZUq6heJR0v6UlJf0z/j36qAnsckT7D/be/SLqt0vpMvX4l/ftZI2lR+ndViX3OTD02S7ot1crW5xEd+sBe4PaIOA0YD8xIl32YBayIiOHAivS4J70PfCYizgBqgUmSxlN5fQLMBNYWPa7EHvc7PyJqi+Y/V1qv/xX4dUT8O+AMCp9rRfUYEevSZ1gLjAX+H/AUFdanpKHArUBdRIymMFGknsrrczTwJQpXJzgDuFTScMrZZ0RkcwOWAhdR+IbvkFQbAqzr6d6KehwAvAScXWl9UvhexQrgM8AzqVZRPRb1ugk4sVWtYnoFjgM2kiZTVGKPbfR8MfC/KrFPYCiwGTiBwqzEZ1K/ldbnFcBDRY//C/CNcvZ5pB/pHyCpBjgT+D1wckRsBUj3J/Vga8CBYZMmYBvwfERUYp8/pPA/6AdFtUrrcb8AlktanS7rAZXV678FtgP/LQ2XPSTpmArrsbV6YFFarqg+I+IN4B7gdWArsCsillNhfQJrgAmSBksaAEym8IXVsvWZRehLOhb4OXBbRPylp/tpS0Tsi8Kv0NXAuPRrYMWQdCmwLSJW93QvHXRORJxF4YquMyRN6OmGWukNnAXcHxFnAv+Xnh9uOqj0ZcrLgCd6upe2pDHwKcAw4G+BYyRd07NdfVRErAW+BzwP/Bp4hcIwdNkc8aEvqQ+FwP9ZRPwild+UNCQ9P4TC0XVFiIidwD8Bk6isPs8BLpO0CVgMfEbST6msHg+IiC3pfhuFMehxVFavLUBL+o0O4EkKPwQqqcdilwAvRcSb6XGl9XkhsDEitkfEHuAXwL+n8vokIh6OiLMiYgLwNrCeMvZ5RIe+JAEPA2sj4gdFTy0DpqXlaRTG+nuMpCpJx6fl/hT+B/4jFdRnRMyOiOqIqKHwa/7/iIhrqKAe95N0jKSB+5cpjO2uoYJ6jYj/A2yWNCKVLqBwifGK6bGVq/jr0A5UXp+vA+MlDUj/7i+gcGK80vpE0knp/t8An6fwuZavz548qVGGkyb/gcLY7h+ApnSbDAymcEJyfbo/oYf7HAO8nPpcA3wr1Suqz6J+z+OvJ3IrrkcK4+WvpFsz8M1K7JXCTK3G9N/9aWBQpfWY+hwA7AD+pqhWiX3eSeFgaQ3w34G+Fdrn/6TwA/4V4IJyf56+DIOZWUaO6OEdMzP7MIe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhn5/xP7x/D57SoLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "age_exited = df[df.Exited==1].Age\n",
    "age_not_exited = df[df.Exited==0].Age\n",
    "print(len(age_exited), len(age_not_exited))\n",
    "plt.hist([age_exited, age_not_exited], color=['red', 'green'], label=['Exited:Yes', 'Exited:No'])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x145c64190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tenure_exited = df[df.Exited==1].Tenure\n",
    "tenure_not_exited = df[df.Exited==0].Tenure\n",
    "plt.hist([tenure_exited, tenure_not_exited], color=['red', 'green'], label=['Exited:Yes', 'Exited:No'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x111202940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "credit_exited = df[df.Exited==1].CreditScore\n",
    "credit_not_exited = df[df.Exited==0].CreditScore\n",
    "plt.hist([credit_exited, credit_not_exited], color=['red', 'green'], label=['Exited:Yes', 'Exited:No'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.Exited==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.get_dummies(data=df, columns=['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619  Female   42       2       0.00              1          1   \n",
       "1             608  Female   41       1   83807.86              1          0   \n",
       "2             502  Female   42       8  159660.80              3          1   \n",
       "3             699  Female   39       1       0.00              2          0   \n",
       "4             850  Female   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771    Male   39       5       0.00              2          1   \n",
       "9996          516    Male   35      10   57369.61              1          1   \n",
       "9997          709  Female   36       7       0.00              1          0   \n",
       "9998          772    Male   42       3   75075.31              2          1   \n",
       "9999          792  Female   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  1        101348.88       1                 1   \n",
       "1                  1        112542.58       0                 0   \n",
       "2                  0        113931.57       1                 1   \n",
       "3                  0         93826.63       0                 1   \n",
       "4                  1         79084.10       0                 0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0                 1   \n",
       "9996               1        101699.77       0                 1   \n",
       "9997               1         42085.58       1                 1   \n",
       "9998               0         92888.52       1                 0   \n",
       "9999               0         38190.78       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                     0                0  \n",
       "1                     0                1  \n",
       "2                     0                0  \n",
       "3                     0                0  \n",
       "4                     0                1  \n",
       "...                 ...              ...  \n",
       "9995                  0                0  \n",
       "9996                  0                0  \n",
       "9997                  0                0  \n",
       "9998                  1                0  \n",
       "9999                  0                0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.replace('Male', 0, inplace=True)\n",
    "# df1.replace('Female', 1, inplace=True)\n",
    "df1['Gender'].replace({'Female':1, 'Male':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       1   42       2       0.00              1          1   \n",
       "1             608       1   41       1   83807.86              1          0   \n",
       "2             502       1   42       8  159660.80              3          1   \n",
       "3             699       1   39       1       0.00              2          0   \n",
       "4             850       1   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       0   39       5       0.00              2          1   \n",
       "9996          516       0   35      10   57369.61              1          1   \n",
       "9997          709       1   36       7       0.00              1          0   \n",
       "9998          772       0   42       3   75075.31              2          1   \n",
       "9999          792       1   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  1        101348.88       1                 1   \n",
       "1                  1        112542.58       0                 0   \n",
       "2                  0        113931.57       1                 1   \n",
       "3                  0         93826.63       0                 1   \n",
       "4                  1         79084.10       0                 0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0                 1   \n",
       "9996               1        101699.77       0                 1   \n",
       "9997               1         42085.58       1                 1   \n",
       "9998               0         92888.52       1                 0   \n",
       "9999               0         38190.78       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                     0                0  \n",
       "1                     0                1  \n",
       "2                     0                0  \n",
       "3                     0                0  \n",
       "4                     0                1  \n",
       "...                 ...              ...  \n",
       "9995                  0                0  \n",
       "9996                  0                0  \n",
       "9997                  0                0  \n",
       "9998                  1                0  \n",
       "9999                  0                0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_col = ['CreditScore', 'Balance', 'EstimatedSalary']\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "s = MinMaxScaler()\n",
    "df1[normal_col] = s.fit_transform(df1[normal_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0        0.538       1   42       2  0.000000              1          1   \n",
       "1        0.516       1   41       1  0.334031              1          0   \n",
       "2        0.304       1   42       8  0.636357              3          1   \n",
       "3        0.698       1   39       1  0.000000              2          0   \n",
       "4        1.000       1   43       2  0.500246              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1         0.506735       1                 1   \n",
       "1               1         0.562709       0                 0   \n",
       "2               0         0.569654       1                 1   \n",
       "3               0         0.469120       0                 1   \n",
       "4               1         0.395400       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                  0                0  \n",
       "1                  0                1  \n",
       "2                  0                0  \n",
       "3                  0                0  \n",
       "4                  0                1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.drop('Exited', axis='columns')\n",
    "y = df1['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(12, input_shape=(12,), activation='relu'),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 630us/step - loss: 0.6690 - accuracy: 0.6896\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 482us/step - loss: 0.5210 - accuracy: 0.7995\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 508us/step - loss: 0.5115 - accuracy: 0.7922\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 523us/step - loss: 0.4961 - accuracy: 0.7918\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4663 - accuracy: 0.8035\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 499us/step - loss: 0.4488 - accuracy: 0.8076\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 511us/step - loss: 0.4566 - accuracy: 0.8072\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 476us/step - loss: 0.4339 - accuracy: 0.8185\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 559us/step - loss: 0.4466 - accuracy: 0.8059\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 481us/step - loss: 0.4434 - accuracy: 0.8172\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 519us/step - loss: 0.4408 - accuracy: 0.8072\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 487us/step - loss: 0.4466 - accuracy: 0.8135\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 508us/step - loss: 0.4277 - accuracy: 0.8186\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 492us/step - loss: 0.4440 - accuracy: 0.8131\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 482us/step - loss: 0.4365 - accuracy: 0.8135\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 518us/step - loss: 0.4375 - accuracy: 0.8084\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 486us/step - loss: 0.4327 - accuracy: 0.8191\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 527us/step - loss: 0.4285 - accuracy: 0.8241\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 484us/step - loss: 0.4285 - accuracy: 0.8220\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 532us/step - loss: 0.4361 - accuracy: 0.8108\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 492us/step - loss: 0.4397 - accuracy: 0.8119\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 522us/step - loss: 0.4348 - accuracy: 0.8143\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 481us/step - loss: 0.4246 - accuracy: 0.8219\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 523us/step - loss: 0.4268 - accuracy: 0.8195\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 496us/step - loss: 0.4445 - accuracy: 0.8022\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 484us/step - loss: 0.4363 - accuracy: 0.8098\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 495us/step - loss: 0.4341 - accuracy: 0.8152\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 492us/step - loss: 0.4319 - accuracy: 0.8119\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.4279 - accuracy: 0.8151\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 495us/step - loss: 0.4317 - accuracy: 0.8150\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 497us/step - loss: 0.4380 - accuracy: 0.8116\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 489us/step - loss: 0.4343 - accuracy: 0.8137\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.4380 - accuracy: 0.8127\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 524us/step - loss: 0.4350 - accuracy: 0.8135\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 483us/step - loss: 0.4324 - accuracy: 0.8154\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.4230 - accuracy: 0.8148\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 482us/step - loss: 0.4317 - accuracy: 0.8134\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 482us/step - loss: 0.4359 - accuracy: 0.8128\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 471us/step - loss: 0.4254 - accuracy: 0.8174\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 475us/step - loss: 0.4337 - accuracy: 0.8088\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 482us/step - loss: 0.4294 - accuracy: 0.8162\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 482us/step - loss: 0.4284 - accuracy: 0.8125\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 481us/step - loss: 0.4363 - accuracy: 0.8106\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 476us/step - loss: 0.4308 - accuracy: 0.8178\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 473us/step - loss: 0.4279 - accuracy: 0.8150\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 480us/step - loss: 0.4323 - accuracy: 0.8060\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 482us/step - loss: 0.4281 - accuracy: 0.8150\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 473us/step - loss: 0.4383 - accuracy: 0.8044\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.4374 - accuracy: 0.8120\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 483us/step - loss: 0.4423 - accuracy: 0.8009\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 492us/step - loss: 0.4451 - accuracy: 0.8055\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 491us/step - loss: 0.4371 - accuracy: 0.8092\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 478us/step - loss: 0.4345 - accuracy: 0.8046\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 481us/step - loss: 0.4333 - accuracy: 0.8117\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4438 - accuracy: 0.8051\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4343 - accuracy: 0.8102\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 480us/step - loss: 0.4288 - accuracy: 0.8159\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4292 - accuracy: 0.8135\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 475us/step - loss: 0.4312 - accuracy: 0.8139\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 471us/step - loss: 0.4461 - accuracy: 0.8031\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 479us/step - loss: 0.4371 - accuracy: 0.8094\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 475us/step - loss: 0.4374 - accuracy: 0.8076\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4348 - accuracy: 0.8093\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4346 - accuracy: 0.8110\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4364 - accuracy: 0.8108\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.4308 - accuracy: 0.8104\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4304 - accuracy: 0.8082\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 472us/step - loss: 0.4311 - accuracy: 0.8115\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.4313 - accuracy: 0.8089\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 473us/step - loss: 0.4372 - accuracy: 0.8091\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 472us/step - loss: 0.4272 - accuracy: 0.8174\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 476us/step - loss: 0.4347 - accuracy: 0.8096\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 529us/step - loss: 0.4465 - accuracy: 0.8034\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 524us/step - loss: 0.4258 - accuracy: 0.8123\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 486us/step - loss: 0.4301 - accuracy: 0.8084\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 503us/step - loss: 0.4280 - accuracy: 0.8160\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 490us/step - loss: 0.4434 - accuracy: 0.8091\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 471us/step - loss: 0.4334 - accuracy: 0.8123\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 469us/step - loss: 0.4248 - accuracy: 0.8165\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 469us/step - loss: 0.4401 - accuracy: 0.8058\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 515us/step - loss: 0.4349 - accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 471us/step - loss: 0.4266 - accuracy: 0.8116\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.4372 - accuracy: 0.8053\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 496us/step - loss: 0.4284 - accuracy: 0.8147\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 475us/step - loss: 0.4246 - accuracy: 0.8130\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 464us/step - loss: 0.4273 - accuracy: 0.8149\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 466us/step - loss: 0.4287 - accuracy: 0.8164\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 483us/step - loss: 0.4235 - accuracy: 0.8218\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 490us/step - loss: 0.4330 - accuracy: 0.8124\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 503us/step - loss: 0.4243 - accuracy: 0.8129\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 467us/step - loss: 0.4268 - accuracy: 0.8140\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 466us/step - loss: 0.4278 - accuracy: 0.8147\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 465us/step - loss: 0.4226 - accuracy: 0.8163\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 455us/step - loss: 0.4239 - accuracy: 0.8184\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 459us/step - loss: 0.4285 - accuracy: 0.8175\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4227 - accuracy: 0.8162\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 521us/step - loss: 0.4335 - accuracy: 0.8056\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 482us/step - loss: 0.4357 - accuracy: 0.8126\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 453us/step - loss: 0.4278 - accuracy: 0.8147\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 455us/step - loss: 0.4320 - accuracy: 0.8066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147ed2820>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 540us/step - loss: 0.4285 - accuracy: 0.8105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4285394251346588, 0.8105000257492065]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1396215 ],\n",
       "       [0.08591831],\n",
       "       [0.09323785],\n",
       "       [0.06966674],\n",
       "       [0.16489187]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(x_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in yp:\n",
    "    if i>0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7054    0\n",
       "442     0\n",
       "3954    0\n",
       "2288    0\n",
       "3196    0\n",
       "6178    0\n",
       "8351    0\n",
       "5658    1\n",
       "2065    0\n",
       "413     1\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1595\n",
      "           1       0.59      0.21      0.31       405\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.71      0.59      0.60      2000\n",
      "weighted avg       0.78      0.81      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize=(7, 5))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sn.heatmap(cm, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.854"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1547+161)/(1547+161+244+48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86 0.77\n"
     ]
    }
   ],
   "source": [
    "print(round(1547/(1547+244), 2), round(161/(161+48), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97 0.4\n"
     ]
    }
   ],
   "source": [
    "print(round(1547/(1547+48), 2), round(161/(244+161), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using dropout regularization\n",
    "modeld = keras.Sequential([\n",
    "    keras.layers.Dense(12, input_shape=(12,), activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeld.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 0s 500us/step - loss: 1.7670 - accuracy: 0.5561\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 550us/step - loss: 0.5993 - accuracy: 0.7822\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 497us/step - loss: 0.5632 - accuracy: 0.7947\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.5560 - accuracy: 0.7817\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 509us/step - loss: 0.5417 - accuracy: 0.7876\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 530us/step - loss: 0.5364 - accuracy: 0.7834\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 490us/step - loss: 0.5272 - accuracy: 0.7909\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 480us/step - loss: 0.5177 - accuracy: 0.7965\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 478us/step - loss: 0.5169 - accuracy: 0.7912\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 473us/step - loss: 0.5037 - accuracy: 0.8008\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 476us/step - loss: 0.4991 - accuracy: 0.7971\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 476us/step - loss: 0.4989 - accuracy: 0.7951\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 517us/step - loss: 0.4905 - accuracy: 0.8004\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 500us/step - loss: 0.4961 - accuracy: 0.7930\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 479us/step - loss: 0.4889 - accuracy: 0.7964\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 502us/step - loss: 0.4786 - accuracy: 0.8010\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 503us/step - loss: 0.4740 - accuracy: 0.8011\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.4864 - accuracy: 0.7911\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.4760 - accuracy: 0.7961\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 500us/step - loss: 0.4658 - accuracy: 0.8002\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 512us/step - loss: 0.4786 - accuracy: 0.7938\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.4636 - accuracy: 0.8014\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 478us/step - loss: 0.4583 - accuracy: 0.8042\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 476us/step - loss: 0.4631 - accuracy: 0.8051\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 499us/step - loss: 0.4684 - accuracy: 0.7973\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 504us/step - loss: 0.4570 - accuracy: 0.8029\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 499us/step - loss: 0.4559 - accuracy: 0.8078\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 497us/step - loss: 0.4513 - accuracy: 0.8080\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 486us/step - loss: 0.4562 - accuracy: 0.8062\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 487us/step - loss: 0.4647 - accuracy: 0.8025\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 496us/step - loss: 0.4544 - accuracy: 0.8086\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.4454 - accuracy: 0.8106\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 483us/step - loss: 0.4602 - accuracy: 0.8018\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 483us/step - loss: 0.4687 - accuracy: 0.7984\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 478us/step - loss: 0.4536 - accuracy: 0.8060\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 478us/step - loss: 0.4708 - accuracy: 0.7980\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 473us/step - loss: 0.4622 - accuracy: 0.8048\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 479us/step - loss: 0.4544 - accuracy: 0.8054\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 501us/step - loss: 0.4539 - accuracy: 0.8068\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 486us/step - loss: 0.4447 - accuracy: 0.8151\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 489us/step - loss: 0.4449 - accuracy: 0.8165\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.4433 - accuracy: 0.8148\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 494us/step - loss: 0.4538 - accuracy: 0.8098\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 497us/step - loss: 0.4408 - accuracy: 0.8168\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.4581 - accuracy: 0.8015\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 478us/step - loss: 0.4520 - accuracy: 0.8082\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 492us/step - loss: 0.4583 - accuracy: 0.8013\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 498us/step - loss: 0.4581 - accuracy: 0.8077\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 498us/step - loss: 0.4409 - accuracy: 0.8138\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 511us/step - loss: 0.4491 - accuracy: 0.8101\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 510us/step - loss: 0.4509 - accuracy: 0.8109\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 507us/step - loss: 0.4324 - accuracy: 0.8195\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 484us/step - loss: 0.4487 - accuracy: 0.8181\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.4448 - accuracy: 0.8188\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 494us/step - loss: 0.4450 - accuracy: 0.8158\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 502us/step - loss: 0.4575 - accuracy: 0.8124\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 498us/step - loss: 0.4375 - accuracy: 0.8198\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 496us/step - loss: 0.4550 - accuracy: 0.8072\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 514us/step - loss: 0.4375 - accuracy: 0.8206\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 488us/step - loss: 0.4336 - accuracy: 0.8227\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 478us/step - loss: 0.4600 - accuracy: 0.8073\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 510us/step - loss: 0.4431 - accuracy: 0.8150\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 495us/step - loss: 0.4438 - accuracy: 0.8137\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 487us/step - loss: 0.4424 - accuracy: 0.8162\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 497us/step - loss: 0.4480 - accuracy: 0.8094\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 486us/step - loss: 0.4430 - accuracy: 0.8136\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.4394 - accuracy: 0.8150\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 478us/step - loss: 0.4515 - accuracy: 0.8099\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 480us/step - loss: 0.4423 - accuracy: 0.8138\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 496us/step - loss: 0.4579 - accuracy: 0.8048\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 494us/step - loss: 0.4547 - accuracy: 0.8056\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 514us/step - loss: 0.4357 - accuracy: 0.8195\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 525us/step - loss: 0.4389 - accuracy: 0.8163\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.4367 - accuracy: 0.8176\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 476us/step - loss: 0.4470 - accuracy: 0.8158\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 510us/step - loss: 0.4590 - accuracy: 0.8049\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 495us/step - loss: 0.4335 - accuracy: 0.8167\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.4396 - accuracy: 0.8137\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 477us/step - loss: 0.4499 - accuracy: 0.8120\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 474us/step - loss: 0.4530 - accuracy: 0.8119\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 508us/step - loss: 0.4559 - accuracy: 0.8030\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 498us/step - loss: 0.4440 - accuracy: 0.8140\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 478us/step - loss: 0.4316 - accuracy: 0.8214\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 511us/step - loss: 0.4408 - accuracy: 0.8136\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 515us/step - loss: 0.4454 - accuracy: 0.8134\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 479us/step - loss: 0.4485 - accuracy: 0.8106\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 475us/step - loss: 0.4486 - accuracy: 0.8097\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 477us/step - loss: 0.4393 - accuracy: 0.8168\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 481us/step - loss: 0.4464 - accuracy: 0.8054\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 480us/step - loss: 0.4458 - accuracy: 0.8126\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 476us/step - loss: 0.4490 - accuracy: 0.8084\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 493us/step - loss: 0.4353 - accuracy: 0.8183\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 496us/step - loss: 0.4484 - accuracy: 0.8117\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 484us/step - loss: 0.4392 - accuracy: 0.8207\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 476us/step - loss: 0.4449 - accuracy: 0.8147\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 479us/step - loss: 0.4365 - accuracy: 0.8173\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 475us/step - loss: 0.4502 - accuracy: 0.8090\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 473us/step - loss: 0.4353 - accuracy: 0.8202\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 480us/step - loss: 0.4374 - accuracy: 0.8171\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 541us/step - loss: 0.4443 - accuracy: 0.8137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x148bbc880>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 457us/step - loss: 0.4378 - accuracy: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43778276443481445, 0.8090000152587891]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(x_train, y_train, x_test, y_test, loss):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(12, input_shape=(12,), activation='relu'),\n",
    "        keras.layers.Dense(8, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss= loss,\n",
    "        metrics='accuracy'\n",
    "    )\n",
    "    model.fit(x_train, y_train, epochs=10)\n",
    "    print(model.evaluate(x_test, y_test))\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = np.round(y_pred)\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "    return y_pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 0s 514us/step - loss: 5.6723 - accuracy: 0.4388\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 487us/step - loss: 0.5864 - accuracy: 0.7534\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 0s 490us/step - loss: 0.5063 - accuracy: 0.7911\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 0s 518us/step - loss: 0.4770 - accuracy: 0.7982\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 0s 497us/step - loss: 0.4551 - accuracy: 0.8045\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 502us/step - loss: 0.4520 - accuracy: 0.8097\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 0s 504us/step - loss: 0.4454 - accuracy: 0.8104\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 0s 500us/step - loss: 0.4379 - accuracy: 0.8187\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 0s 501us/step - loss: 0.4504 - accuracy: 0.8085\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 0s 505us/step - loss: 0.4404 - accuracy: 0.8115\n",
      "63/63 [==============================] - 0s 538us/step - loss: 0.4447 - accuracy: 0.8170\n",
      "[0.4447227716445923, 0.8169999718666077]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89      1595\n",
      "           1       0.61      0.26      0.36       405\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.73      0.61      0.63      2000\n",
      "weighted avg       0.79      0.82      0.79      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(x_train, y_train, x_test, y_test, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7963"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exited_0_count, exited_1_count = df1['Exited'].value_counts()\n",
    "exited_0_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_exited_1 = df1[df1.Exited==1]\n",
    "sample_exited_0 = df1[df1.Exited==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7963"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_exited_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_exited_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_exited_0_under = sample_exited_0.sample(exited_1_count)\n",
    "df_under = pd.concat([sample_exited_0_under, sample_exited_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2037\n",
       "0    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_under.drop('Exited', axis=1)\n",
    "y = df_under['Exited']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1630\n",
       "1    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "102/102 [==============================] - 0s 597us/step - loss: 1.4980 - accuracy: 0.5091\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 570us/step - loss: 0.6499 - accuracy: 0.6407\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 558us/step - loss: 0.6440 - accuracy: 0.6573\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 593us/step - loss: 0.6304 - accuracy: 0.6539\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 561us/step - loss: 0.6116 - accuracy: 0.6834\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 557us/step - loss: 0.6089 - accuracy: 0.6907\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 559us/step - loss: 0.6016 - accuracy: 0.6865\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 529us/step - loss: 0.6052 - accuracy: 0.6902\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 538us/step - loss: 0.5972 - accuracy: 0.6982\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 527us/step - loss: 0.6022 - accuracy: 0.6885\n",
      "26/26 [==============================] - 0s 573us/step - loss: 0.5773 - accuracy: 0.7166\n",
      "[0.5773006081581116, 0.716564416885376]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       407\n",
      "           1       0.72      0.70      0.71       408\n",
      "\n",
      "    accuracy                           0.72       815\n",
      "   macro avg       0.72      0.72      0.72       815\n",
      "weighted avg       0.72      0.72      0.72       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(x_train, y_train, x_test, y_test, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_exited_1_over = sample_exited_1.sample(exited_0_count, replace=True)\n",
    "df_over = pd.concat([sample_exited_0, sample_exited_1_over], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_over.drop('Exited', axis=1)\n",
    "y = df_over['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6370\n",
       "0    6370\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "399/399 [==============================] - 1s 540us/step - loss: 0.6812 - accuracy: 0.5489\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 0s 567us/step - loss: 0.6124 - accuracy: 0.6751\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 0s 526us/step - loss: 0.5869 - accuracy: 0.6943\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 0s 552us/step - loss: 0.5809 - accuracy: 0.7021\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 0s 507us/step - loss: 0.5751 - accuracy: 0.7072\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 0s 513us/step - loss: 0.5757 - accuracy: 0.7142\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 0s 563us/step - loss: 0.5780 - accuracy: 0.7130\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 0s 516us/step - loss: 0.5737 - accuracy: 0.7071\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 0s 521us/step - loss: 0.5630 - accuracy: 0.7210\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 0s 527us/step - loss: 0.5662 - accuracy: 0.7157\n",
      "100/100 [==============================] - 0s 454us/step - loss: 0.5403 - accuracy: 0.7332\n",
      "[0.5402590036392212, 0.7332077622413635]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.75      1593\n",
      "           1       0.76      0.69      0.72      1593\n",
      "\n",
      "    accuracy                           0.73      3186\n",
      "   macro avg       0.74      0.73      0.73      3186\n",
      "weighted avg       0.74      0.73      0.73      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(x_train, y_train, x_test, y_test, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df1.drop('Exited', axis=1)\n",
    "y = df1['Exited']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy=\"minority\")\n",
    "x_sm, y_sm = smote.fit_resample(x, y)\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "399/399 [==============================] - 1s 548us/step - loss: 0.8615 - accuracy: 0.5276\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 0s 548us/step - loss: 0.6177 - accuracy: 0.6908\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 0s 574us/step - loss: 0.5900 - accuracy: 0.7134\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 0s 556us/step - loss: 0.5662 - accuracy: 0.7281\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 0s 549us/step - loss: 0.5634 - accuracy: 0.7167\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 0s 547us/step - loss: 0.5533 - accuracy: 0.7275\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 0s 525us/step - loss: 0.5515 - accuracy: 0.7268\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 0s 510us/step - loss: 0.5473 - accuracy: 0.7263\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 0s 514us/step - loss: 0.5383 - accuracy: 0.7328\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 0s 533us/step - loss: 0.5379 - accuracy: 0.7290\n",
      "100/100 [==============================] - 0s 434us/step - loss: 0.5277 - accuracy: 0.7326\n",
      "[0.5277157425880432, 0.7325800657272339]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73      1593\n",
      "           1       0.72      0.75      0.74      1593\n",
      "\n",
      "    accuracy                           0.73      3186\n",
      "   macro avg       0.73      0.73      0.73      3186\n",
      "weighted avg       0.73      0.73      0.73      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(x_train, y_train, x_test, y_test, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emsemble with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.554265</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339721</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>0.852</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371163</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980432</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>0.664</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325318</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.648</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>0.426077</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "5710        0.856       0   34       5  0.554265              2          0   \n",
       "3745        0.852       1   37       1  0.371163              2          1   \n",
       "5429        0.664       1   48       7  0.000000              2          1   \n",
       "551         0.648       0   47       6  0.426077              1          1   \n",
       "8967        0.970       0   25       7  0.000000              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
       "5710               0         0.339721                 1                  0   \n",
       "3745               1         0.980432                 0                  1   \n",
       "5429               0         0.325318                 1                  0   \n",
       "551                1         0.010339                 0                  1   \n",
       "8967               1         0.417230                 1                  0   \n",
       "\n",
       "      Geography_Spain  Exited  \n",
       "5710                0       0  \n",
       "3745                0       0  \n",
       "5429                0       0  \n",
       "551                 0       1  \n",
       "8967                0       0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = x_train.copy()\n",
    "df2['Exited'] = y_train\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6370\n",
       "1    1630\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_exited_0 = df2[df2.Exited==0]\n",
    "df2_exited_1 = df2[df2.Exited==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "    x_train = df.drop('Exited', axis=1)\n",
    "    y_train = df.Exited\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "102/102 [==============================] - 0s 603us/step - loss: 4.6046 - accuracy: 0.5066\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 579us/step - loss: 1.0131 - accuracy: 0.4852\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 566us/step - loss: 0.7973 - accuracy: 0.4827\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 568us/step - loss: 0.7303 - accuracy: 0.4910\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 554us/step - loss: 0.6974 - accuracy: 0.5014\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 530us/step - loss: 0.6772 - accuracy: 0.4988\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 526us/step - loss: 0.6644 - accuracy: 0.6330\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 542us/step - loss: 0.6476 - accuracy: 0.6698\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 521us/step - loss: 0.6396 - accuracy: 0.6744\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 538us/step - loss: 0.6290 - accuracy: 0.6751\n",
      "63/63 [==============================] - 0s 488us/step - loss: 0.5898 - accuracy: 0.6865\n",
      "[0.5897519588470459, 0.6865000128746033]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78      1593\n",
      "           1       0.36      0.69      0.47       407\n",
      "\n",
      "    accuracy                           0.69      2000\n",
      "   macro avg       0.63      0.69      0.62      2000\n",
      "weighted avg       0.79      0.69      0.71      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_train_batch(df2_exited_0, df2_exited_1, 0, 1630)\n",
    "y_pred1 = ANN(x_train, y_train, x_test, y_test, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "102/102 [==============================] - 0s 610us/step - loss: 0.9669 - accuracy: 0.5184\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 633us/step - loss: 0.6695 - accuracy: 0.5786\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 549us/step - loss: 0.6546 - accuracy: 0.5951\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 547us/step - loss: 0.6499 - accuracy: 0.6209\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 535us/step - loss: 0.6354 - accuracy: 0.6418\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 548us/step - loss: 0.6311 - accuracy: 0.6528\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 541us/step - loss: 0.6202 - accuracy: 0.6624\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 557us/step - loss: 0.5981 - accuracy: 0.6911\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 538us/step - loss: 0.6021 - accuracy: 0.6730\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 540us/step - loss: 0.5964 - accuracy: 0.6856\n",
      "63/63 [==============================] - 0s 480us/step - loss: 0.5713 - accuracy: 0.7030\n",
      "[0.5713251233100891, 0.703000009059906]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.80      1593\n",
      "           1       0.36      0.62      0.46       407\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.62      0.67      0.63      2000\n",
      "weighted avg       0.78      0.70      0.73      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_train_batch(df2_exited_0, df2_exited_1, 1630, 3260)\n",
    "y_pred2 = ANN(x_train, y_train, x_test, y_test, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "102/102 [==============================] - 0s 607us/step - loss: 1.4631 - accuracy: 0.5073\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 573us/step - loss: 0.6813 - accuracy: 0.5696\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 573us/step - loss: 0.6690 - accuracy: 0.5778\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 549us/step - loss: 0.6525 - accuracy: 0.6322\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 533us/step - loss: 0.6353 - accuracy: 0.6640\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 603us/step - loss: 0.6150 - accuracy: 0.6811\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 551us/step - loss: 0.6064 - accuracy: 0.6746\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 549us/step - loss: 0.5990 - accuracy: 0.6882\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 532us/step - loss: 0.5915 - accuracy: 0.6921\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 555us/step - loss: 0.5794 - accuracy: 0.7001\n",
      "63/63 [==============================] - 0s 506us/step - loss: 0.5483 - accuracy: 0.7250\n",
      "[0.5483164191246033, 0.7250000238418579]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82      1593\n",
      "           1       0.38      0.56      0.45       407\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.63      0.66      0.63      2000\n",
      "weighted avg       0.77      0.72      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_train_batch(df2_exited_0, df2_exited_1, 3260, 4890)\n",
    "y_pred3 = ANN(x_train, y_train, x_test, y_test, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 0s 592us/step - loss: 0.7048 - accuracy: 0.5393\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 0s 577us/step - loss: 0.6683 - accuracy: 0.5862\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 0s 546us/step - loss: 0.6557 - accuracy: 0.6138\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 0s 570us/step - loss: 0.6418 - accuracy: 0.6327\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 0s 595us/step - loss: 0.6285 - accuracy: 0.6541\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 0s 606us/step - loss: 0.6153 - accuracy: 0.6669\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 0s 556us/step - loss: 0.6032 - accuracy: 0.6932\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 0s 542us/step - loss: 0.5876 - accuracy: 0.6843\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 0s 529us/step - loss: 0.6001 - accuracy: 0.6752\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 0s 553us/step - loss: 0.5911 - accuracy: 0.6866\n",
      "63/63 [==============================] - 0s 473us/step - loss: 0.6503 - accuracy: 0.6275\n",
      "[0.6503220796585083, 0.6274999976158142]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72      1593\n",
      "           1       0.32      0.75      0.45       407\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.61      0.67      0.58      2000\n",
      "weighted avg       0.79      0.63      0.66      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_train_batch(df2_exited_0, df2_exited_1, 4890, 6370)\n",
    "y_pred4 = ANN(x_train, y_train, x_test, y_test, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = []\n",
    "for i in range(len(y_pred1)):\n",
    "    sum = y_pred1[i] + y_pred2[i] + y_pred3[i] + y_pred4[i]\n",
    "    if sum>2:\n",
    "        y_pred_final.append(1)\n",
    "    else:\n",
    "        y_pred_final.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      1593\n",
      "           1       0.37      0.62      0.46       407\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.63      0.67      0.63      2000\n",
      "weighted avg       0.78      0.71      0.73      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
